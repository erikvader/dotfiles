#!/bin/python

import argparse as A
import urllib.request as U
import urllib.parse as P
import json
import re
from contextlib import contextmanager
import zipfile as Z
import os
from math import log10, ceil
from bisect import insort
import sys
import subprocess as S

class MangadexException(Exception):
   pass

class StatusBar:
   def __init__(self, name, maximum):
      self.name = name
      self.maximum = maximum
      self.cur = 0
      self.is_term = False
      if os.isatty(sys.stdout.fileno()) and os.environ.get("TERM", "dumb") != "dumb":
         self.is_term = True
         self.term_width = os.get_terminal_size().columns
         self._output()

   def _clear_line(self):
      if self.is_term:
         print("\r\x1b[K", end="")

   def _output(self):
      self._clear_line()
      beg = "{} ({}/{}) [".format(self.name, self.cur, self.maximum)
      print(beg, end="")
      left = self.term_width - len(beg) - 1
      filled = int((self.cur/self.maximum)*left)
      print("#"*filled, end="")
      print("-"*(left-filled), end="")
      print("]", end="", flush=True)

   def step(self):
      self.cur += 1
      if self.cur >= self.maximum and not self.is_term:
         print("{} ... done".format(self.name))
      elif self.is_term:
         self._output()

class MangadexDownloader:
   HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64)"}
   API_URL = "https://mangadex.org/api"

   def __init__(self, manga_json):
      self.manga_json = manga_json
      self.chapter_info = {}
      self._extract_chapter_info()

   def get_manga_json(self):
      return self.manga_json

   def get_title(self):
      return self.manga_json["manga"]["title"]

   def get_reported_last_chapter(self):
      return self.manga_json["manga"]["last_chapter"]

   def get_author(self):
      return self.manga_json["manga"]["author"]

   def get_mal_id(self):
      return self.manga_json["manga"]["links"].get("mal", None)

   def set_preferred_group(self, group):
      self.manga_json["settings"]["preferred_group"] = group

   def get_available_chapters(self):
      return sorted(self.chapter_info.keys(), key=float)

   def is_chapter(self, chap_num):
      return chap_num in self.chapter_info

   def get_chapter_title(self, chap_num):
      if not self.is_chapter(chap_num):
         raise MangadexException("{} not an available chapter".format(chap_num))
      chap_id = self.chapter_info[chap_num]
      return self.manga_json["chapter"][chap_id]["title"]

   def download_chapter(self, chap_num):
      if not self.is_chapter(chap_num):
         raise MangadexException("{} not an available chapter".format(chap_num))

      return MangadexDownloader.ChapterDownloader(self.chapter_info[chap_num])

   def update(self):
      url = self.manga_json["url"]
      settings = self.manga_json["settings"]
      new = MangadexDownloader.from_url(url)
      self.manga_json = new.manga_json
      self.manga_json["url"] = url
      self.manga_json["settings"] = settings
      self.chapter_info = new.chapter_info

   def _extract_chapter_info(self):
      all_chapters = self.manga_json["chapter"]
      pref_group = self.manga_json["settings"].get("preferred_group", None)

      for chap_id,vals in all_chapters.items():
         chap_num = vals["chapter"]
         if vals["lang_code"] != "gb":
            continue

         if (chap_num not in self.chapter_info or
             (pref_group and vals["group_name"] == pref_group)):
            self.chapter_info[chap_num] = chap_id

   @classmethod
   def from_url(cls, url):
      manga_info = MangadexDownloader.fetch_json(
         MangadexDownloader._extract_manga_id(url),
         "manga"
      )
      manga_info["url"] = url
      manga_info["settings"] = {}
      return cls(manga_info)

   @staticmethod
   def _extract_manga_id(url):
      # https://mangadex.org/title/2434/grappler-baki
      m = re.match(r"^https?://mangadex.org/title/([0-9]+)/?", url)
      if not m:
         raise MangadexException("invalid url")
      return m[1]

   @staticmethod
   @contextmanager
   def fetch(url, getvars=None):
      if getvars:
         getvars = P.urlencode(getvars)
         url = MangadexDownloader.API_URL + "?" + getvars
      req = U.Request(url, headers=MangadexDownloader.HEADERS)
      with U.urlopen(req) as response:
         # TODO: kolla om 200?
         yield response

   @staticmethod
   def fetch_json(mid, mtype):
      getvars = {"id": mid, "type": mtype, "baseURL": "/api"}
      with MangadexDownloader.fetch(MangadexDownloader.API_URL, getvars=getvars) as mjson:
         return json.load(mjson)

   class ChapterDownloader:
      def __init__(self, chap_id):
         self.chap_id = chap_id
         self.chap_json = MangadexDownloader.fetch_json(
            self.chap_id,
            "chapter"
         )
         self.cur_page = 0
         self.extractor = re.compile(r"^[a-zA-z]*([0-9]+)\.(.+)$")

      def get_title(self):
         return self.chap_json["title"]

      def amount_of_pages(self):
         return len(self.chap_json["page_array"])

      def has_next(self):
         return self.cur_page < self.amount_of_pages()

      def next_page_info(self):
         if not self.has_next():
            raise Exception("no next page")

         m = self.extractor.match(self.chap_json["page_array"][self.cur_page])
         return int(m[1]), m[2]

      @contextmanager
      def next_page(self):
         if not self.has_next():
            raise Exception("no next page")

         url = "{}/{}/{}".format(
            self.chap_json["server"].rstrip("/"),
            self.chap_json["hash"],
            self.chap_json["page_array"][self.cur_page]
         )
         with MangadexDownloader.fetch(url) as image:
            yield image

         self.cur_page += 1

class Manager:
   SYNCFILE = ".mangadex"

   def __init__(self, path, downloader=None, syncdata=None, localdata=None):
      self.path = path
      if not os.path.isdir(self.path):
         raise MangadexException("not a valid directory")

      self.syncfile = os.path.join(path, Manager.SYNCFILE)
      if not os.path.isfile(self.syncfile) and (syncdata is None or localdata is None):
         raise MangadexException("can't find sync file")

      self.localdata = localdata
      if syncdata is None or self.localdata is None:
         syncdata, self.localdata = self._load_syncfile()

      self.downloader = downloader or MangadexDownloader(syncdata)

   @classmethod
   def new(cls, basedir, url):
      md = MangadexDownloader.from_url(url)
      folder_name = md.get_title()
      folder_name = "".join([c for c in folder_name if c.isalnum() or c == ' ']).strip()
      manga_dir = os.path.join(basedir, folder_name)
      os.mkdir(manga_dir)
      n = cls(manga_dir, downloader=md, syncdata=md.get_manga_json(), localdata={"unread": []})
      n.save_syncfile()
      return n

   def _load_syncfile(self):
      with open(self.syncfile, "r") as f:
         everything = json.load(f)
         return everything["sync"], everything["local"]

   def save_syncfile(self):
      with open(self.syncfile, "w") as f:
         everything = {"sync": self.downloader.get_manga_json(), "local": self.localdata}
         json.dump(everything, f)

   def update(self):
      self.downloader.update()

   def _query_fs(self):
      x = re.compile(r"^Ch\.([0-9\.]+) - (.+)\.cbz$")
      for f in os.scandir(self.path):
         if f.name == Manager.SYNCFILE:
            continue
         m = x.match(f.name)
         yield (m[1], m[2], m[0])

   def list_all_chapters(self):
      local = set(x[0] for x in self._query_fs())
      for c in self.downloader.get_available_chapters():
         yield (
            c,                                               # chapter number
            self.downloader.get_chapter_title(c),            # chapter title
            c in local,                                      # is downloaded?
            c not in self.localdata["unread"] and c in local # is read?
         )

   def get_stats(self):
      downloaded = 0
      total = 0
      first_down = None
      last_down = None
      for chnum, _, down, _ in self.list_all_chapters():
         total += 1
         if down:
            downloaded += 1
            first_down = min(first_down, chnum, key=float) if first_down else chnum
            last_down = max(last_down, chnum, key=float) if last_down else chnum

      return {
         "title": self.downloader.get_title(),
         "mal": self.downloader.get_mal_id(),
         "author": self.downloader.get_author(),
         "reported_last_chapter": self.downloader.get_reported_last_chapter(),
         "next_chapter": self.find_first_unread_chapter(),
         "latest_downloaded": last_down,
         "first_downloaded": first_down,
         "total_available_chapters": total,
         "total_downloaded_chapters": downloaded
      }

   def find_first_unread_chapter(self):
      l = self.localdata["unread"]
      return l[0] if l else None

   def find_latest_downloaded_chapter(self):
      return max((x[0] for x in self._query_fs()), key=float, default=None)

   def download_chapter(self, chap_num):
      cd = self.downloader.download_chapter(chap_num)
      filename = "Ch.{} - {}.cbz".format(chap_num, cd.get_title())
      filepath = os.path.join(self.path, filename)
      if os.path.exists(filepath):
         raise MangadexException("chapter {} is already downloaded".format(chap_num))
      padlen = ceil(log10(cd.amount_of_pages()))
      bar = StatusBar("Ch.{}".format(chap_num), cd.amount_of_pages())
      with Z.ZipFile(filepath, "w") as zf:
         while cd.has_next():
            i, ext = cd.next_page_info()
            pagename = ("{:0"+str(padlen)+"d}.{}").format(i, ext)
            with cd.next_page() as image:
               zf.writestr(pagename, image.read())
               bar.step()
      insort(self.localdata["unread"], chap_num)

   def download_next(self, n=1):
      assert(n>0)
      avail = self.downloader.get_available_chapters()
      latest = self.find_latest_downloaded_chapter()
      if latest:
         start = avail.index(latest)+1 # TODO: bisect for binary search??
      else:
         start = 0
      if start >= len(avail):
         raise MangadexException("no new chapters to download")
      for i in range(start, min(start+n, len(avail))):
         self.download_chapter(avail[i])

   def set_read(self, chap_num, flag):
      if not self.downloader.is_chapter(chap_num):
         raise MangadexException("{} is not a valid chapter".format(chap_num))

      if flag:
         try:
            self.localdata["unread"].remove(chap_num)
         except ValueError:
            pass # chap_num not in localdata
      else:
         insort(self.localdata["unread"], chap_num)

   def _find_chapter_file(self, chap_num):
      for ch, _, filename in self._query_fs():
         if ch == chap_num:
            return filename
      #pylint: disable=useless-else-on-loop
      else:
         raise MangadexException("Couldn't find file for chapter {}".format(chap_num))

   def read(self):
      n = self.find_first_unread_chapter()
      if not n:
         raise MangadexException("No more chapters to read")

      filename = self._find_chapter_file(n)
      p = S.run(["sxiv_zip", "--", os.path.join(self.path, filename)])
      p.check_returncode()
      self.set_read(n, True)

def main_status(parsed):
   man = Manager(".")
   if parsed.verbose:
      print("Downloaded, read, chapter, title")
      for chnum, title, down, read in man.list_all_chapters():
         print("{}, {}, Ch.{} - {}".format(down, read, chnum, title))
   else:
      stats = man.get_stats()
      print(
'''\
Title:          {title}
Author:         {author}
Myanimelist:    https://myanimelist.net/manga/{mal}
Latest chapter: {reported_last_chapter}
Read next:      {next_chapter}
Total chapters: {total_available_chapters}
Downloaded:     {total_downloaded_chapters} ({first_downloaded} - {latest_downloaded})
'''.format(**stats), end="")

def main_sync(_parsed):
   man = Manager(".")
   man.update()
   man.save_syncfile()

def main():
   parser = A.ArgumentParser(description="Mangadex downloader and reader")
   subparsers = parser.add_subparsers(dest="command", required=True)

   statusP = subparsers.add_parser("status", help="Display current status",
                                   description="Displays general information about the current manga.")
   statusP.add_argument("-v", "--verbose", action="store_true",
                        help="list information about every individual chapter")

   _syncP = subparsers.add_parser("sync", help="Update manga metadata",
                                  description="Redownloads metadata from Mangadex")

   parsed = parser.parse_args()

   print(parsed)
   if parsed.command == "status":
      main_status(parsed)
   elif parsed.command == "sync":
      main_sync(parsed)
   # m = Manager.new(".", "https://mangadex.org/title/2434/grappler-baki")
   # m = Manager("Grappler Baki")
   # m.read()
   # m.save_syncfile()
   # m.download_chapter("2")

if __name__ == "__main__":
   try:
      main()
   except MangadexException as e:
      print("Oppsies, {}".format(str(e)), file=sys.stderr, flush=True)
      exit(1)
